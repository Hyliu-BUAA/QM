{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tour of the `Bayesian Optimization package`\n",
    "Website\n",
    "-------\n",
    "1. https://github.com/fmfn/BayesianOptimization\n",
    "2. \n",
    "\n",
    "Content\n",
    "-------\n",
    "1. This is a constrained `global optimization package` built upon `bayesian inference` and `guassian process`, that `find the maximum value of an unknown function` in as few iterations as possible. This technique is particularly suited for optimization of high cost functions, situations where the `balance between exploration and exploitation` is important.\n",
    "    - `bayesian inference`: 提供下一步搜索方向\n",
    "    - `guassian process`: 作为代理模型\n",
    "2. `Bayesian optimization` works by constructing `a posterior distribution of functions (gaussian process) that best describes the function` you want to describe.\n",
    "    - As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of `which regions in parameter space are worth exploring` and which not.\n",
    "3. As you iterate over and over, the algorithm balances its need of `exploration and exploitation` taking into account what it knows about the target function.\n",
    "     - At each step a `Gaussian Process` is fitted to the known samples (points previously explored), and the posterior distribution, combined with a `exploration strategy`(`UCB`, `EI`, `PI`)\n",
    "4. This process is designed to `minimize the number of steps` required to fina a combination of parameters that are close to the `optimal combination`.\n",
    "    - To do so, this method uses a `proxy optimization function (finding the maximum of the acqusition function)` that, albeit still a hard problem, is cheaper (in the computational sense) and common tools can be employed.\n",
    "    - Therefore Bayesian Optimization is most adequate for situations where sampling the function to be optimized is a very expensive endeavor. (`因此，贝叶斯优化最适合于对要优化的函数进行采样是非常昂贵的工作的情况。`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "\n",
    "### scipy 1.8.0 中 minimize() 方法改变，所以我们需要 scipy1.7.0 版本\n",
    "assert (scipy.__version__ == '1.7.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Specifying the function to be optimized\n",
    "DISCLAIMER ( 免责声明)\n",
    "----------\n",
    "1. We know exactly how the output of the function below depends on its parameters. \n",
    "2. <font color=\"red\">Obviously this is just an example ,and `you shouldn't expect to know it in a real scenario.`</font>\n",
    "3. <font color=\"73DB90\">`All you need` in order to use this package (and more generally, this technique) is a function $f$ that `takes a known set of parameters` and `outputs a real number`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_function(x, y):\n",
    "    '''\n",
    "    Description\n",
    "    -----------\n",
    "        1. Function with unknown internals we wish to maximize.\n",
    "        2. This is just serving as an example, for all intents and \n",
    "        purposes think of the internals of this function, i.e.: the process\n",
    "        which generates its output values, as unknown.\n",
    "    '''\n",
    "    return -x ** 2 - (y -1) ** 2 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Getting Started\n",
    "1. All we need to get started is to init a `BaysianOptimization` object specifying a function to be optimized `f`, and its parameters with their corresponding bounds--`pbounds`.\n",
    "2. This is a `constrained optimization technique`, so you must specify the `minimum and maximum values that can be probed for each parameter` in order for it to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'x': (2, 4), 'y': (-3, 3)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "            f=black_box_function,\n",
    "            pbounds=pbounds,\n",
    "            verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "            random_state=1, # 注意一定要指定 random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The BayesianOptimization object will work out of the box without much tuning needed. The main method you should be aware of is `maximize()`, which does exactly what you think it does.\n",
    "4. There are many parameters you can pass to `maximize()`, nonetheless, the most important ones are:\n",
    "     - `n_iter`: How many `steps of bayesian optimization` you want to perform. The more steps the more likely to find a good maximum you are.\n",
    "     - `init_points`: How many `steps of random exploration` you want to perform. Random exploration can help by diversifying the exploration space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-7.135   \u001b[0m | \u001b[0m 2.834   \u001b[0m | \u001b[0m 1.322   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-7.78    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m-1.186   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-7.11    \u001b[0m | \u001b[95m 2.218   \u001b[0m | \u001b[95m-0.7867  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-12.4    \u001b[0m | \u001b[0m 3.66    \u001b[0m | \u001b[0m 0.9608  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-6.999   \u001b[0m | \u001b[95m 2.23    \u001b[0m | \u001b[95m-0.7392  \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "        init_points=2,\n",
    "        n_iter=3,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The best combination of parameters and target value found can be accessed via the property `bo.max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': -6.999472814518675, 'params': {'x': 2.2303920156083024, 'y': -0.7392021938893159}}\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. While the list of all parameters probed and their corresponding target values is available via the property `bo.res`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: \n",
      "\t{'target': -7.135455292718879, 'params': {'x': 2.8340440094051482, 'y': 1.3219469606529488}}\n",
      "Iteration 1: \n",
      "\t{'target': -7.779531005607566, 'params': {'x': 2.0002287496346898, 'y': -1.1860045642089614}}\n",
      "Iteration 2: \n",
      "\t{'target': -7.109925819441113, 'params': {'x': 2.2175526295255183, 'y': -0.7867249801593896}}\n",
      "Iteration 3: \n",
      "\t{'target': -12.397162416009818, 'params': {'x': 3.660003815774634, 'y': 0.9608275029525108}}\n",
      "Iteration 4: \n",
      "\t{'target': -6.999472814518675, 'params': {'x': 2.2303920156083024, 'y': -0.7392021938893159}}\n"
     ]
    }
   ],
   "source": [
    "for idx_step, res in enumerate(optimizer.res):\n",
    "    print(f\"Iteration {idx_step}: \\n\\t{res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Changing bounds \n",
    "1. During the optimization process you may realize the bounds chosen for some parameters are not adequate.\n",
    "    - For these situations you can invoke the method `set_bounds()` to alter them.\n",
    "    - You can pass any combination of existing parameters and their associated new bounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-2.942   \u001b[0m | \u001b[95m 1.98    \u001b[0m | \u001b[95m 0.8567  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.4597  \u001b[0m | \u001b[95m 1.096   \u001b[0m | \u001b[95m 1.508   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.5304  \u001b[0m | \u001b[95m-0.6807  \u001b[0m | \u001b[95m 1.079   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-5.33    \u001b[0m | \u001b[0m-1.526   \u001b[0m | \u001b[0m 3.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-5.419   \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m-0.5552  \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.set_bounds({'x':(-2, 3)})\n",
    "\n",
    "optimizer.maximize(\n",
    "        init_points=0,\n",
    "        n_iter=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Guiding the optimization\n",
    "1. It is often the case that we `have an idea of regions of the parameter space` where the maximum of our function might lie.\n",
    "2. For these situations the `BayesianOptimization` objects allows the user to `specify specific points to be probed`.\n",
    "3. By default these will be explored lazily (`lazy=True`), \n",
    "    - meaning these points will be evaluated `only the next time you call maximize()`.\n",
    "    - <font color=\"red\">This probing process happens before the `gaussian process` takes over</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索 {\"x\": 0.5, \"y\":0.7}\n",
    "optimizer.probe(\n",
    "        params={\"x\": 0.5, \"y\":0.7},\n",
    "        lazy=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Or as an `iterable`. Beware that the order has to be `alphabetical`. You can usee `optimizer.space.keys` for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y']\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.space.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索 {\"x\": -0.3, \"y\":0.1}\n",
    "optimizer.probe(\n",
    "    params=[-0.3, 0.1],\n",
    "    lazy=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.66    \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.7     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m-0.3     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points=0,\n",
    "    n_iter=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. `Saving`, `loading` and `restarting`\n",
    "1. By default you can follow the progress of your optimization by setting `verbose>0`.\n",
    "2. If you need more control over `logging/alerting` you will need to use an observer.\n",
    "3. For more information about observers checkout the advanced tour notebook. Here we will only see how to use the native `JSONLogger` object `to save to and load progress from files`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Saving progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The observer paradigm works by:\n",
    "   1. Instantiating (实例化) an `observer` object.\n",
    "   2. Tying the `observer` object to a particular `event` fired by an `optimizer`.\n",
    "2. The `BayesianOptimization` objects fires a number of internal events during optimization, in particular, `everytime it probes the function and obtains a new parameter-target combination` it will fire an `Events.OPTIMIZATION_STEP` event, which our `logger` will listen to.\n",
    "\n",
    "Caveat\n",
    "------\n",
    "1. The logger will not look back at previously probed points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = JSONLogger(path='/Users/mac/我的文件/Notebook/Quantum_Mechanics/algorithm_implementation/5.GaussianProcess+贝叶斯优化/notes/BayesianOptimization_package/tmp/logs.json')\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-12.48   \u001b[0m | \u001b[0m-1.266   \u001b[0m | \u001b[0m-2.446   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-3.854   \u001b[0m | \u001b[0m-1.069   \u001b[0m | \u001b[0m-0.9266  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-3.594   \u001b[0m | \u001b[0m 0.7709  \u001b[0m | \u001b[0m 3.0     \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 0.8238  \u001b[0m | \u001b[95m 0.03434 \u001b[0m | \u001b[95m 1.418   \u001b[0m |\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.9721  \u001b[0m | \u001b[95m-0.1051  \u001b[0m | \u001b[95m 0.87    \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Loading progress\n",
    "1. Naturally, if you stored progress you will be able to load that onto a new instance of `BayesianOptimization` object. \n",
    "2. The easiest way to do it is by invoking the `load_logs()` function, from the `util` submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt.util import load_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "new_optimizer = BayesianOptimization(\n",
    "    f=black_box_function,\n",
    "    pbounds={'x':(-2, 2), 'y':(-2, 2)},\n",
    "    verbose=2,\n",
    "    random_state=7,\n",
    ")\n",
    "print(len(new_optimizer.space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bayes_opt.bayesian_optimization.BayesianOptimization at 0x7fb5d8a6be50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_logs(new_optimizer,\n",
    "        logs=['/Users/mac/我的文件/Notebook/Quantum_Mechanics/algorithm_implementation/5.GaussianProcess+贝叶斯优化/notes/BayesianOptimization_package/tmp/logs.json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New optimizer is now aware of 5 points.\n"
     ]
    }
   ],
   "source": [
    "print(\"New optimizer is now aware of {} points.\".format(len(new_optimizer.space)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-3.548   \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m 1.74    \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-3.041   \u001b[0m | \u001b[0m 1.914   \u001b[0m | \u001b[0m 0.3844  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-12.0    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-3.969   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.984   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.7794  \u001b[0m | \u001b[0m-1.238   \u001b[0m | \u001b[0m 0.5022  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.529   \u001b[0m | \u001b[0m 0.685   \u001b[0m | \u001b[0m 0.9576  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.2987  \u001b[0m | \u001b[0m 0.1242  \u001b[0m | \u001b[0m 0.1718  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9544  \u001b[0m | \u001b[0m 0.2123  \u001b[0m | \u001b[0m 0.9766  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7157  \u001b[0m | \u001b[0m-0.437   \u001b[0m | \u001b[0m 1.305   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.983   \u001b[0m | \u001b[95m-0.06785 \u001b[0m | \u001b[95m 1.111   \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "new_optimizer.maximize(\n",
    "    init_points=0,\n",
    "    n_iter=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Complete code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-7.135   \u001b[0m | \u001b[0m 2.834   \u001b[0m | \u001b[0m 1.322   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-7.78    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m-1.186   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-7.11    \u001b[0m | \u001b[95m 2.218   \u001b[0m | \u001b[95m-0.7867  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-12.4    \u001b[0m | \u001b[0m 3.66    \u001b[0m | \u001b[0m 0.9608  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-6.999   \u001b[0m | \u001b[95m 2.23    \u001b[0m | \u001b[95m-0.7392  \u001b[0m |\n",
      "=================================================\n",
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-2.942   \u001b[0m | \u001b[95m 1.98    \u001b[0m | \u001b[95m 0.8567  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.4597  \u001b[0m | \u001b[95m 1.096   \u001b[0m | \u001b[95m 1.508   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.5304  \u001b[0m | \u001b[95m-0.6807  \u001b[0m | \u001b[95m 1.079   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-5.33    \u001b[0m | \u001b[0m-1.526   \u001b[0m | \u001b[0m 3.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-5.419   \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m-0.5552  \u001b[0m |\n",
      "=================================================\n",
      "['x', 'y']\n",
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.66    \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.7     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m-0.3     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "assert (scipy.__version__ == \"1.7.0\")\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "def black_box_function(x, y):\n",
    "    return -x ** 2 - (y-1) ** 2 + 1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pbounds = {'x': (2, 4),\n",
    "                'y':(-3, 3)}\n",
    "\n",
    "    ### 1. Initialize\n",
    "    bo = BayesianOptimization(\n",
    "                f=black_box_function,\n",
    "                pbounds=pbounds,\n",
    "                verbose=2,\n",
    "                random_state=1,\n",
    "                )\n",
    "\n",
    "\n",
    "    ### 2. Run\n",
    "    bo.maximize(\n",
    "            init_points=2,\n",
    "            n_iter=3,\n",
    "            )\n",
    "\n",
    "    ### 3. change pbounds\n",
    "    bo.set_bounds(\n",
    "            new_bounds={\"x\": (-2, 3)},\n",
    "            )\n",
    "    bo.maximize(\n",
    "            init_points=0, \n",
    "            n_iter=5,\n",
    "            )\n",
    "    \n",
    "\n",
    "    ### 4. probe \n",
    "    # way1: dict\n",
    "    bo.probe(\n",
    "            params={\"x\": 0.5, \"y\":0.7},\n",
    "            lazy=True,\n",
    "            )\n",
    "    \n",
    "    # way 2: list\n",
    "    print(bo.space.keys)\n",
    "    bo.probe(\n",
    "            params=[-0.3, 0.1],\n",
    "            lazy=True\n",
    "            )\n",
    "    \n",
    "    bo.maximize(\n",
    "            init_points=0,\n",
    "            n_iter=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Next Steps\n",
    "1. This tour should be enough to cover most usage scenarios of this package. If, however, you feel like you need to know more, please checkout the advanced-tour notebook. There you will be able to find other, more advanced features of this package that could be what you're looking for. Also, browse the examples folder for implementation tips and ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b361d90544c21c7e570702d0c4d23653c8dcac4c1ecf309667aae54eeacb0d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
