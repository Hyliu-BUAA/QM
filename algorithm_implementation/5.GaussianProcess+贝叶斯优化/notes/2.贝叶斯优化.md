# 0. 贝叶斯优化 (`Bayesian Optimization`)
<font color="steelblue" size="4">

Website
-------
1. https://zhuanlan.zhihu.com/p/150555551
2. https://zhuanlan.zhihu.com/p/390373572

Introduction
------------
1. `Bayesian optimization` 可以在某个区间最大化某个函数
$$max_{x \in \mathcal{X}} f(x)$$
2. 如果这个函数计算比较容易，甚至还可以知道它的梯度，那事情就好办了，一阶、二阶优化算法换着上就完事。
3. 但现实往往没有那么理想，这个函数的一阶、二阶导数信息我们可能是没有的，甚至`计算一次函数的值都很费劲`
   1. （给定一个 $x$，计算 $f(x)$ 的计算量很大，比如神经网络中的超参数优化）
   2. 这时候就要求助 `gradient-free 的优化算法`了，这类算法也很多了，`贝叶斯优化`就属于`无梯度优化算法`中的一种，<font color="red">它希望在尽可能少的试验情况下去尽可能获得优化命题的`全局最优解`。</font>

</font>

# 1. `Bayesian Optimization` 概述
## 1.1. `代理模型` && `Acquisition Function`
<font color="steelblue" size="4">

1. 由于我们要优化的这个`函数计算量太大`(比如`DFT-NEB计算势垒`)，我们需要使用一个`代理模型`来近似 $f(x)$。
2. `Bayesian Optimization` 中使用的代理模型是`高斯过程 (Gaussian Process)`。
3. 假设我们对待优化函数 $f(x)$ 的`先验 (prior)`为高斯过程。经过一定的试验我们有了`数据 (evidence)`。然后根据 `贝叶斯定理 (Bayesian pricipal)` 就可以得到这个函数的`后验分布`。
4. 有了这个`后验分布`，我们`需要考虑的是下一次试验点在哪里进一步收集数据`。因此需要构造一个 `acquisition function` 用于指导搜索方向（选择下一个试验点）。
5. 然后去试验，得到数据后更新 `代理模型` 的后验分布，反复进行。

</font>

## 1.2. Bayesian Optimization 过程
<font color="steelblue" size="4">

1. for t = 1, 2, ... do
2. Find $x_t$ by optimizing the `acquisition function` over the `Gaussian Process`: $x_t = arg\max_x u(x|D_{1:t-1})$
3. Sample the `objective function`: $y_t = f(x_t) + \epsilon_t$
4. Augment the data $D_{1:t} = \{ D_{1:t-1}, (x_t; y_t) \}$ and `update the GP`
5. end for

</font>


# 2. Gaussian Process (高斯过程)
<font color="steelblue" size="4">

1. 高斯过程是多元高斯分布向无穷维的扩展。
    - `高斯分布`是`随机变量的分布`
    - `高斯过程`是`函数的分布`，它由`均值向量`和`协方差矩阵(核函数)`确定
$$f(\vec{x}) \sim \mathcal{GP}(\vec{\mu}, k(\vec{x}, \vec{x^{'}}))$$
2. 在 t 次试验后，我们有数据 $\{ x_{1:t}, f_{1:t} \}$，由于高斯过程上任意点 $f_{t+1}$ 与之前的观测数据`服从联合高斯分布`。进一步可以得到预测分布：
$$P(f_{t+1}| D_{1:t, x_{t+1}}) \sim \mathcal{N}(\mu_t(x_{t+1}), \sigma_t^2(x_{t+1}))$$
3. 我们可以`根据高斯过程的后验分布`对这个未知函数在任意位置的值做出`预测均值、方差`。

</font>


# 3. `Acquisition Function` -- 指明搜索方向
<font color="steelblue" size="4">

1. 为了`搜到目标函数的最优解`，`贝叶斯优化`选择的搜索方向为：
    - `预测值大`的位置
    - `不确定性大`的位置
2. 因此 `Bayesian Optimization` 中很多工作关注点在于 `acquisition function` 的设计

</font>

## 3.1. 最大化提升`概率` -- `PI`


## 3.2. 最大化提升`量` -- `EI`


## 3.3. 最大化`置信上界` -- `UCB`